#!/bin/bash

# Personnal aliases
alias edssh='code ${HOME}/.ssh/config'
alias rea='. ${HOME}/.zsh_aliases && . ${HOME}/.zshenv'
alias eda='code ${HOME}/.zsh_aliases'
alias ede='code ${HOME}/.zshenv'
alias edc='code ${HOME}/.zsh_custom'
alias eds='code ${HOME}/.config/starship.toml'
alias edd='code $(devbox global path)/devbox.json'

alias connect='proxy_start && update_vscode_jenkins_plugin_token && sfa'

alias c='code'
alias cr='code -r'

alias dr='devbox run'
alias tt='devbox run test'

GOPATH=$(go env GOPATH)
export PATH="$PATH:$GOPATH/bin"

alias sc='search_code'
function search_code() {
  grep -I -R "$1" "${HOME}/dev"
}

alias findz="find ./* -type f | fzf --preview 'bat --color=always {}' --preview-window '~3'"

# https://github.com/ryanoasis/nerd-fonts/releases/download/v3.2.1/FiraCode.zip
function install_fonts() {
  font_url=$1
  if [[ $font_url == "" ]]
  then
    echo "${RED}[Error] missing parameter : font URL"
    return 1
  fi
  font_name=${font_url##*/} && \
    wget "${font_url}" && \
    unzip "${font_name}" -d ~/.fonts && \
    fc-cache -fv
}

function update() {
  devbox version update
  eval "$(devbox global shellenv --recompute)"
  refresh-global
  devbox global update
  [[ -f "./devbox.json" ]] && devbox update
  refresh-global
  update_aws_sso_cli
  kubectl krew upgrade
}

function backup() {
  sudo cp -Lr "${HOME}/.zsh_history" "${HOME}/.zshenv" "${HOME}/.zsh_custom" "${HOME}/.zsh_aliases" \
    "${HOME}/.config/starship.toml" "${HOME}/.gitconfig" \
    "${HOME}/.ssh" "${HOME}/.gpg" "${HOME}/.aws" "${HOME}/.config/google-chrome/Default/Bookmarks" \
    /etc/cntlm.conf /etc/redsocks.conf /usr/local/sbin/redsocks-iptables "$(devbox global path)/devbox.json" \
    /media/sf_sharedfolder
  sudo mkdir -p /media/sf_sharedfolder/.kube
  sudo cp -r "${HOME}/.kube/kubeconfig"* "/media/sf_sharedfolder/.kube"

  # copy in my github repo
  sudo cp "${HOME}/.zsh_custom" \
    "${HOME}/.config/starship.toml" "$(devbox global path)/devbox.json" \
    "${HOME}/dev/devbox-global"
  pushd "${HOME}/dev/devbox-global" > /dev/null || return
  git add .zsh_custom starship.toml > /dev/null
  git commit -m "Update config files" > /dev/null
  git add devbox.json > /dev/null
  git commit -m "Update packages list" > /dev/null
  git push
  popd > /dev/null 2>&1 || true
}

function free_space() {
  echo "------------------------------------------------"
  echo "Free space"
  echo "------------------------------------------------"
  echo "Disk space before cleaning :"
  df -h /dev/sda2
  echo "------------------------------------------------"
  sudo apt-get -y clean
  sudo apt -y autoclean
  sudo apt-get -y autoremove --purge
  [[ -d "${HOME}/.cache/cloud-code/installer" ]] && rm -rf "${HOME}/.cache/cloud-code/installer"
  # go clean -cache -modcache -i -r
  sudo rm -rf /var/lib/snapd/cache/* > /dev/null 2>&1
  sudo journalctl --rotate
  sudo journalctl --vacuum-time=1s > /dev/null 2>&1
  docker system prune -a -f --volumes
  for item in $(find "${HOME}" -name ".terraform" -type d | grep -E "^/home"); do rm -rf "$item"; done
  devbox global run -- nix store gc --extra-experimental-features nix-command
  echo "------------------------------------------------"
  echo "Disk space after cleaning :"
  df -h /dev/sda2
  echo "------------------------------------------------"
}

########################################
#                Jenkins
########################################
alias ut='update_vscode_jenkins_plugin_token'
function configure_vscode_jenkins_plugin_in_all_repos() {
  for git_folder in "${HOME}/dev/"*/.git
  do
    [[ -d "$git_folder" ]] || return

    configure_vscode_jenkins_plugin "${git_folder%/.git}" false
  done
}
function configure_vscode_jenkins_plugin() {
  git_root_folder=$1
  [[ $git_root_folder == "" ]] && git_root_folder=$(pwd)
  # skip repos without Jenkinsfile
  [[ -f "${git_root_folder}/Jenkinsfile" ]] || return
  echo "=> Configure VScode jenkins plugin for ${git_root_folder##*/}"
  pushd "${git_root_folder}" > /dev/null || return
  git_url=$(git remote get-url origin)
  main_branch_name=$(get_main_branch_name)
  popd > /dev/null 2>&1 || true
  git_project_name=$(echo "$git_url" | perl -lne 'print $1 if /git@.+:(.+)\.git/')
  if [[ $git_project_name == "" ]]
  then
    echo -e "${RED}Error, malformed git URL : '$git_url' don't match 'git@xxx:xxx.git'"
    return 1
  fi
  jenkins_organization_name="$(echo "${git_project_name%%/*}" | tr '[:lower:]' '[:upper:]')"
  cat <<EOF >"${git_root_folder}/.jenkins"
{
"url": "https://xxx/job/${jenkins_organization_name}/job/${git_project_name//\//%2F}/job/${main_branch_name}/",
"username": "xxx",
"password": "xxx"
}
EOF
  echo "OK"

  if ! grep '.jenkins' "${git_root_folder}/.gitignore" > /dev/null
  then
    echo "Configure gitignore"
    cat <<EOF >>"${git_root_folder}/.gitignore"

# Jenkins status VScode plugin configuration file, don't commit it because it contains your Jenkins personal token !
.jenkins

EOF
    pushd "${git_root_folder}" > /dev/null || return
    git add .gitignore > /dev/null
    git commit -m "Ignore VScode jenkins plugin config file" > /dev/null
    popd > /dev/null 2>&1 || true
  fi
  [[ $2 != "false" ]] && update_vscode_jenkins_plugin_token ""
}

function update_vscode_jenkins_plugin_token() {
  new_token=$1
  if [[ -z $new_token ]]
  then
    # shellcheck disable=SC1091
    source "$HOME/.ssh/jenkins.sh"
    result=$("${HOME}/dev/oam.ci.jenkins-automation/create-personal-token.sh" -q --hostname "xxx" --username "${JENKINS_GTP_SA_USER}" -n "VSCode_plugin")
  fi
  new_token=$(echo "$result" | tr -d '\n')
  if ! [[ $new_token =~ ^[0-9a-z]+$ ]] 
  then
    echo "[ERROR] $result"
  else
    export JENKINS_GTP_TOKEN="$new_token"
    nb=0
    for git_folder in "${HOME}/dev/"*/.git
    do
      [[ -d "$git_folder" ]] || continue

      git_root_folder="${git_folder%/.git}"
      if [[ -f "${git_root_folder}/.jenkins" ]]
      then
        sed -i "s/\"password\": \".*\"/\"password\": \"${new_token}\"/" "${git_root_folder}/.jenkins"
        nb=$((nb+1))
      fi
    done
    echo "$nb tokens updated under \"${HOME}/dev\""
  fi
}

function allow_jenkins_slave_ssh() {
  ssh admin@xxx << EOF
sudo sed -i 's/^AllowTcpForwarding.*/AllowTcpForwarding yes/' /etc/ssh/sshd_config
sudo systemctl restart sshd
EOF
}

function trigger_jenkins_scan() {
  git_root_folder=$1
  [[ $git_root_folder == "" ]] && git_root_folder=$(pwd)

  if [[ ! -f "$git_root_folder/.jenkins" ]];
  then
    echo -e "${RED}Error, '.jenkins' config file not found in $git_root_folder"
    return 1
  fi

  if [[ ! -f "$HOME/.last_update_vscode_jenkins_plugin_token" || $(cat "$HOME/.last_update_vscode_jenkins_plugin_token") != $(date '+%d/%m/%Y') ]]
  then
    update_vscode_jenkins_plugin_token
    date '+%d/%m/%Y' > "$HOME/.last_update_vscode_jenkins_plugin_token"
  fi

  url=$(jq -r '.url' "$git_root_folder/.jenkins")
  job_root_url="${url%/job/*/}"
  username=$(jq -r '.username' "$git_root_folder/.jenkins")
  password=$(jq -r '.password' "$git_root_folder/.jenkins")
  curl -u "$username:$password" -X POST "$job_root_url/build"
}

function fix_jenkins_vscode_plugin() {
  for file in "${HOME}/.vscode/extensions/alefragnani.jenkins-status-"*"/dist/extension.js"
  do
    if [[ ! -f "${file}.backup" ]]
    then
      cp "$file" "${file}.backup"
    fi
    echo '==> Remove 3 occurrence of "o.Uri.parse(" in the file (don'\''t forget to remove also the corresponding closing bracket)'
    echo '==> Replace .openInJenkinsConsoleOutput",(()=>{c.getStatus(p,u,l).then((e=>{e.connectionStatus===o.ConnectionStatus.Connected?r.env.openExternal(this.settingNameToUrl[s.name]+e.buildNr.toString()+"/console'
    echo 'by .openInJenkinsConsoleOutput",(()=>{c.getStatus(p,u,l).then((e=>{e.connectionStatus===o.ConnectionStatus.Connected?r.env.openExternal(this.settingNameToUrl[s.name].replaceAll('\''%2F'\'','\''%252F'\'').replace(/\/job\/([^\/]+)\/job\/([^\/]+)\/job\//, '\''/blue/organizations/jenkins/$1%2F$2/detail/'\'')+e.buildNr.toString()'
    echo '==> Replace this.statusBarItems[s.name].name=t,this.statusBarItems[s.name].command="Jenkins."+s.name+".openInJenkins"'
    echo 'by this.statusBarItems[s.name].name=t,this.statusBarItems[s.name].command="Jenkins."+s.name+".openInJenkinsConsoleOutput"'
    echo 'close the file and restart VS Code'
    code "$file"
  done
}

########################################
#                Git
########################################
alias gicp='git cherry-pick'
alias gil='git log --graph --oneline --color --decorate'
alias gir="git_rebase_origin"
alias gipc="git_propagate_commits"
alias giri='git rebase -i '
alias girst='git reset --hard '
alias gip='git update-index --chmod=+x '
alias giap='git commit --amend --no-edit && git push -f'
alias gidb='deleteOldBranches'
alias girsto='git_reset_to_origin'
alias girc='GIT_EDITOR=true git rebase --continue'
alias gdb='delete_git_branch'
alias cc='clonecode'

function delete_git_branch() {
  if [[ $1 != "" ]]
  then
    git push --delete origin $1
  fi
  deleteOldBranches
}

function close_git_branch() {
  source_branch=$1
  if [[ -z $source_branch ]]
  then
    source_branch=$(get_main_branch_name)
  fi
  git_rebase_origin "$source_branch"
  current_branch=$(git rev-parse --abbrev-ref HEAD)
  git checkout "$source_branch"
  git pull
  git merge "$current_branch"
  git branch -D "$current_branch"
  git push --delete origin "$current_branch"
}

function git_propagate_commits() {
  target_branch=$1
  if [[ -z $target_branch ]]
  then
    echo "${RED}[ERROR] target_branch is required"
    return 1
  fi
  current_branch=$(git rev-parse --abbrev-ref HEAD)
  git checkout "$target_branch" && \
    git pull && \
    git rebase "$current_branch" && \
    if [[ $2 == "" ]]
    then
      git push -f && \
      git checkout "$current_branch"
    fi
}

function git_rebase_origin() {
  source_branch=$1
  if [[ -z $source_branch ]]
  then
    source_branch=$(get_main_branch_name)
  fi
  git fetch && git rebase "origin/$source_branch"
}

function get_main_branch_name() {
  if [[ ! -z $(git ls-remote --heads origin master) ]];
  then
    echo "master"
  else
    echo "main"
  fi
}

function git_reset_to_origin() {
  current_branch=$(git rev-parse --abbrev-ref HEAD)
  if [[ $current_branch != "" ]];
  then
    git reset --hard "origin/$current_branch"
  fi
}

function deleteOldBranches() {
  git fetch -p
  git branch -vv | grep ': gone]'| grep -v "\*" | awk '{ print $1; }' | xargs -r git branch -D
  branches=$(git branch -a)
  echo "$branches"
}

function deleteOldBranchesInEachRepo() {
  for git_folder in "${HOME}/dev/"*/.git
  do
    [[ -d "$git_folder" ]] || continue
    cd "${git_folder%/.git}" && deleteOldBranches
  done
}

function clonecode() {
  git_url=$1
  target_dir=$(echo "$git_url" | perl -lne 'print $1 if /git@.+:(.+)\.git/' | tr '/' '.')
  if [[ "$target_dir" == "" ]]
  then
    target_dir=$(echo "$git_url" | perl -lne 'print $1 if /https:\/\/.+?\/(.+)\.git/' | tr '/' '.')
  fi
  if [[ "$target_dir" == "" ]]
  then
    echo -e "${RED}Error, malformed git URL : '$git_url' don't match 'git@xxx:xxx.git' nor 'https://xxx/xxx.git'"
    return 1
  fi
  if [[ ! -d "${HOME}/dev/$target_dir" ]]
  then
    echo "=> Git clone \"$target_dir\""
    git clone "$git_url" "${HOME}/dev/$target_dir"
  fi
  echo "=> Open \"$target_dir\" in VScode"
  code "${HOME}/dev/$target_dir"
  configure_vscode_jenkins_plugin "${HOME}/dev/$target_dir"
}


function custom_rebase() {
  if [[ "$1" == "" ]];
  then
    echo -e "${RED}Error, one argument required : git ref of new desired base"
    return 1
  fi
  tmp=$(mktemp)
  git archive --format=tar HEAD > "$tmp"
  git reset --hard $1
  if [[ "$2" == "-d" ]];
  then
    rm -rf *
  fi
  tar xf "$tmp"
  rm -f "$tmp"
}


############################################################
#                          Proxy
############################################################

DEFAULT="\e[39m"
GREEN="\e[32m"
RED="\e[31m"

alias cls='clock_sync'
function clock_sync() {
  sudo /usr/sbin/VBoxService --timesync-set-start --timesync-set-on-restore --timesync-set-threshold 1000 --timesync-interval 5000
  return
}

# Check internet access, fail after 15s
function check_internet_connection() {
  if [[ "$(curl -m 5 -L -s -o /dev/null -I -w '%{http_code}' http://www.google.fr)" == "200" ]]
  then
    echo -e "${GREEN}OK"
    return 0
  else
    echo -e "${RED}KO"
    return 1
  fi
}

# Check corporate access, fail after 15s
function check_corporate_connection() {
  if [[ "$(curl -m 5 -L -s -o /dev/null -I -w '%{http_code}' https://repo.int.be.continental.cloud)" == "200" ]]
  then
    echo -e "${GREEN}OK"
    return 0
  else
    echo -e "${RED}KO"
    return 1
  fi
}

# Check DNS
function check_dns() {
  if dig +short www.google.fr +time=5 +tries=3 > /dev/null
  then
    echo -e "${GREEN}OK"
    return 0
  else
    echo -e "${RED}KO"
    return 1
  fi
}

alias prs='proxy_status'
function proxy_status() {
  echo -en "${DEFAULT}CNTLM : ${GREEN}"; sudo systemctl is-active cntlm.service
  echo -en "${DEFAULT}REDSOCKS : ${GREEN}"; sudo systemctl is-active redsocks.service
  echo -en "${DEFAULT}INTERNET CONNECTION : "; check_internet_connection
  echo -en "${DEFAULT}CORPORATE_CONNECTION : "; check_corporate_connection
  echo -en "${DEFAULT}DNS_CONNECTION : "; check_dns
  echo -en "${DEFAULT}"
}

# Proxy management
alias proxy_unset='unset http{s,}_proxy && unset HTTP{S,}_PROXY && unset FTP_PROXY && unset ftp_proxy && unset ALL_PROXY && unset all_proxy'
alias proxy_start='sudo systemctl daemon-reload && sudo systemctl start cntlm.service && sudo systemctl start redsocks.service; sleep 2; proxy_status'
alias proxy_stop='sudo systemctl stop redsocks.service cntlm.service; sleep 2; proxy_status'

alias rep='proxy_restart'
function proxy_restart() {
  sudo systemctl daemon-reload
  sudo systemctl restart cntlm 
  sudo systemctl restart redsocks 
  sudo systemctl restart systemd-resolved
  sleep 2
  proxy_status
}

alias red='dns_restart'
function dns_restart() {
  sudo systemctl daemon-reload
  sudo systemctl restart systemd-resolved
  sleep 5
  proxy_status
}

function cntlm_hash_passwd() {
  cntlm -u uia59190@cw01 -H
  echo "sudo gedit /etc/cntlm.conf"
}

########################################
#             Docker
########################################
function docker_prune() {
    docker container prune
    docker image prune
}
function docker_run() {
    docker run --rm -it --network=host -u root -v "$(pwd):/current" -w /current --entrypoint "" -v "${HOME}/.ssh:/root/.ssh" -v "${HOME}/.aws:/root/.aws" -e AWS_PROFILE -e AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY -e AWS_DEFAULT_REGION -e ANSIBLE_SSH_ARGS="-F /dev/null" "$@"
}
function docker_bash() {
    docker_run "$1" bash
}
function docker_sh() {
    docker_run "$1" sh
}
function docker_enter() {
    docker_bash $1 || docker_sh $1
}

alias dop='docker_prune'
alias dor='docker_run'
alias dob='docker_bash'
alias dos='docker_sh'
alias doi='docker images'
alias doe='docker_enter'

# Portainer
alias portainer='docker run -d -p 9001:9000 --name portainer -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer'
alias portainer_stop='docker rm -f portainer'

########################################
#                 K8S
########################################
# shellcheck disable=SC1090
source <(kubectl completion zsh)

# alias kon='kubeon'
alias kns='kubens'
alias kcx='set_kubeconfigs && kubectx'
alias kga='kubectl get all'
alias kgn='kubectl get nodes'
alias kgp='kubectl get po'
alias kgd='kubectl get deploy'
alias kgap='kubectl get app -n argocd'
alias kgas='kubectl get appset -n argocd'
alias kg='kubectl get'
alias kgy='kubectl get -o yaml'
alias kgj='kubectl get -o json'
alias kd='kubectl describe'
alias kdr='kubectl describe rollout'
alias kda='kubectl describe analysisruns'
alias klf='kubectl logs -f --tail 100'
alias kkyv='kubectl describe polr | grep "Result: \+fail" -B10'
alias kgpf='kubectl get po -A | grep -v Running | grep -v Completed'
alias kgpfw='kubectl get po -A -o wide | grep -v Running | grep -v Completed'
alias kgps='kubectl get pods -A -o wide --field-selector spec.nodeName='
alias kgi='kubectl get pods -o jsonpath="{..image}" | tr -s "[[:space:]]" "\n" | sort | uniq -c'
alias kgia='kubectl get pods -A -o jsonpath="{..image}" | tr -s "[[:space:]]" "\n" | sort | uniq -c'
alias kgda="get_po_disruption_issue"

alias kv='view_k8s_manifest'
function view_k8s_manifest () {
  temp_file=$(mktemp --suffix=.yaml)
  kubectl get -o yaml "$@" > "$temp_file"
  code "$temp_file"
}

function disable_kyverno () {
  kubectl label ns "$1" webhooks.kyverno.io/exclude=''
}
function enable_kyverno () {
  kubectl label ns "$1" webhooks.kyverno.io/exclude-
}

function open_cloud_init() {
  temp_file=$(mktemp --suffix=.log)
  scp "${1?}:/var/log/cloud-init-output.log" "$temp_file"
  code "$temp_file"
}

function get_po_disruption_issue () {
  k get pdb -A -o json | jq -r '.items[] | select(.status.disruptionsAllowed == 0) | "\(.metadata.namespace)/\(.metadata.name)"'
}

function k_get_all() {
  # shellcheck disable=SC2068
  NAMES="$(kubectl api-resources \
                  --namespaced \
                  --verbs list \
                  -o name | tr '\n' ,)" \
  && export NAMES && kubectl get "${NAMES:0:-1}" --show-kind $@
}

function k_remove_finalizers() {
  kubectl patch $1 --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]'
}

function k_force_remove_finalizers() {
  namespace=$1
  kubectl get ns "$namespace" -o json | jq '.spec = {"finalizers":[]}' | kubectl replace --raw "/api/v1/namespaces/$namespace/finalize" -f
}

function kg_composition_errors() {
  kubectl get "$1" "$2" -o=jsonpath='{.spec.resourceRef}{" "}{.spec.resourceRefs}' | jq '.[] | select( .name == null)'
}


function argocd_sync_app() {
  app=${1?}
  argocd login cd.argoproj.io --core
  argocd app terminate-op "$app"
  argocd app sync "$app"
}

function enable_argocd() {
  kubectl scale sts,deploy --replicas 1 --all -n argocd
}

function disable_argocd() {
  kubectl scale sts,deploy --replicas 0 --all -n argocd
}

function kubeops() {
  echo "Searching kube config..."
  if [ -z "$1" ]; then
    if [[ -e $KUBECONFIG ]]; then 
      echo "No argument => loading current KUBECONFIG ($KUBECONFIG) !"
      CONFIGFILE=$(basename $KUBECONFIG)
    else
      echo "No KUBECONFIG : Either set KUBECONFIG env var or pass a kubeconfig name as argument"
      echo ""
      echo "Usage: ${0} <kube-config-name> "
      echo ""
      echo "------------------------------------"
      echo "List of available kube config :"
      echo "------------------------------------"
      find ${HOME}/.kube/ -maxdepth 1 -name "*config*" -exec sh -c 'basename "$1"' find-sh {} \;
      return
    fi
  else
    CONFIGFILE=${1}
  fi
  echo "Using kube config : ${CONFIGFILE}..."
  docker run -it --net=host -v "${HOME}:${HOME}" hjacobs/kube-ops-view --kubeconfig-path="${HOME}/.kube/${CONFIGFILE}"
}

function k() {
  kubectl "$@"
}

function kimg () {
  cat << EOF > "${HOME}/.kube/k8s-images.fmt"
NAMESPACE            NAME           IMAGE            INIT_IMAGE
metadata.namespace   metadata.name  spec.containers[0].image    spec.initContainers[0].image
EOF
  kubectl get pods -o custom-columns-file="${HOME}/.kube/k8s-images.fmt" "$@"
}

function kssh {
  # shellcheck disable=SC2001
  ip=$(echo "$1" | sed 's/ip-\([0-9]\{1,3\}-[0-9]\{1,3\}-[0-9]\{1,3\}-[0-9]\{1,3\}\).*/\1/')
  ip=${ip//-/.}
  ssh "$ip"
}

function convert_to_kustomize {
  dir=${1:=.}
  [[ -f ".version" ]] && source .version
  pushd "$dir" || return
  [[ -f "kustomization.yaml" ]] && rm "kustomization.yaml"
  [[ -d "result" ]] && rm -rf "result"
  kustomize create
  [[ $ADDON_NAMESPACE != "" ]] && kustomize edit set namespace "$ADDON_NAMESPACE"
  find . -type f -name '*.yaml' -not -path "./kustomization.yaml" -exec sh -c 'kustomize edit add resource "$1"' find-sh {} \;
  mkdir "result"
  kustomize build . -o result
  popd > /dev/null 2>&1 || true
}

############################################################
#                       Terraform
############################################################

function tfinit() {
  rm -rf ".terraform"
  mkdir ".terraform"
  cp "$HOME/.terraform.d/providers_cache/.terraform.lock.hcl" ".terraform"
  cp -R "$HOME/.terraform.d/providers_cache/providers" ".terraform"
  terraform init -reconfigure -get=true -upgrade=true
}

function get_tf_backend_s3_path() {
  bucket=$(grep -ohP 'bucket\s*=\s+"\K[^"]+' backend.tf)
  workspace_key_prefix=$(grep -ohP 'workspace_key_prefix\s*=\s+"\K[^"]+' backend.tf)
  key=$(grep -ohP 'key\s*=\s+"\K[^"]+' backend.tf)

  echo "s3://${bucket}/${workspace_key_prefix}/${TERRAFORM_WORKSPACE:=PROD}/${key}"
}
function show_tf_backend() {
  aws --profile backend s3 cp "$(get_tf_backend_s3_path)" -
}
function pull_tf_backend() {
  aws --profile backend s3 cp "$(get_tf_backend_s3_path)" "$(grep -ohP 'key\s*=\s+"\K[^"]+' backend.tf).json"
}
function push_tf_backend() {
  aws --profile backend s3 cp "$(get_tf_backend_s3_path)" "$(get_tf_backend_s3_path).backup" \
  && echo 'backup created !' \
  && aws --profile backend s3 cp "$(grep -ohP 'key\s*=\s+"\K[^"]+' backend.tf).json" "$(get_tf_backend_s3_path)"
}

##################################################################
#                          Certificates
##################################################################
function gencert() {
  mkdir -p /tmp/cert
  echo "test DNS command : dig -t txt +short _acme-challenge.${1} @8.8.8.8"
  docker run --rm -it --network=host -v /tmp/cert:/etc/letsencrypt certbot/certbot certonly --manual -d $1 -d \*.$1 --preferred-challenges dns && \
  sudo mv "${HOME}/.certs/${1}.pem" "${HOME}/.certs/${1}_$(date '+%Y%m%d').pem" | true && \
  sudo mv "${HOME}/.certs/${1}.key" "${HOME}/.certs/${1}_$(date '+%Y%m%d').key" | true && \
  sudo cp "/tmp/cert/live/${1}/fullchain.pem" "${HOME}/.certs/${1}.pem" && \
  sudo cp "/tmp/cert/live/${1}/privkey.pem" "${HOME}/.certs/${1}.key" && \
  sudo chown "${USER}:" "${HOME}/.certs/${1}."* && \
  sudo rm -rf /tmp/cert
  ls -lrt "${HOME}/.certs"
}

##################################################################
#                              SSH
##################################################################
function import_ssh_key() {
  if [[ "$1" == "" ]];
  then
    ls /media/sf_sharedfolder/.ssh
  else
    cp "/media/sf_sharedfolder/.ssh/$1" "${HOME}/.ssh"
    chmod 400 "${HOME}/.ssh/$1"
  fi
}

function write_public_ssh_key() {
  ssh-keygen -y -f "${HOME}/.ssh/$1" > "${HOME}/.ssh/${1%.pem}.pub"
  chmod 644 "${HOME}/.ssh/${1%.pem}.pub"
}

function set_ssh_config() {
  if [[ "$1" == "" ]];
  then
    ln -sf "${HOME}/.ssh/config_global" "${HOME}/.ssh/config"
  else
    ln -sf "${HOME}/.ssh/config_$1" "${HOME}/.ssh/config"
  fi
}

function manage_pgp() {
  gpg --list-secret-keys --keyid-format LONG
  echo "Create new key : vi ${HOME}/.gpg/config && gpg --batch --gen-key config"
  echo "Delete key : gpg --delete-secret-and-public-key --batch --yes XXXXXXXXXXXXXXXXX"
  echo "Import key : gpg --import ${HOME}/.gpg/xxxxxxxxxxx.asc"
  echo "Export public key : gpg --export --armor XXXXXXXXXXXXXXXXX > ${HOME}/.gpg/gpg_xxxxxxxxxxx_public.asc && chmod 644 ${HOME}/.gpg/gpg_xxxxxxxxxxx_public.asc"
  echo "Export private key : gpg --export-secret-keys --armor XXXXXXXXXXXXXXXXX > ${HOME}/.gpg/gpg_xxxxxxxxxxx.asc && chmod 400 ${HOME}/.gpg/gpg_xxxxxxxxxxx.asc"
}

#################################
# AWS
#################################

function check_aws_connection() {
  echo -en "${DEFAULT}Check AWS connection using '${1:=current}' profile : "
  [[ $1 != "" ]] && profile_param="--profile $1"
  # shellcheck disable=SC2086
  if eval "aws sts get-caller-identity $profile_param"
  then
    echo -e "${GREEN}OK"
    return 0
  else
    echo -e "${RED}KO"
    return 1
  fi
}

function aws_decode-authorization-message() {
  aws sts decode-authorization-message --encoded-message $1 --query 'DecodedMessage' --output text | jq
}

#################################
# GCP
#################################

function get_gke_kubeconfig {
  CLUSTER_NAME=$1
  if [[ "$CLUSTER_NAME" == "" ]];
  then
    echo -e "${RED}Error, 1 argument required : CLUSTER_NAME"
    echo -e "${DEFAULT}------"
    gcloud container clusters list
    return 1
  fi
  export KUBECONFIG="${HOME}/.kube/kubeconfig_gcp_${CLUSTER_NAME}"
  [[ -f $KUBECONFIG ]] && rm "$KUBECONFIG"
  touch "$KUBECONFIG"
  gcloud container clusters get-credentials "${CLUSTER_NAME}" --region europe-west3 --project gcp1002d-i3x5x6ms
  # kubeon
  kubectl cluster-info
  kubectl get ns
}
